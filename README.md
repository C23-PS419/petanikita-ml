# PetaniKita Machine Learning

This is a repository for machine learning model of PetaniKita app.

## Setup

We recommend using Google Cloud TPU VM for training the model. You can follow the
instruction [here](https://cloud.google.com/tpu/docs/quickstart) to setup the VM.

Other than that, you can also use any local or cloud instance with GPU to train the model.

## Training

To train the model, simply run the `train.py` by using appropriate flags.

```shell
python3 src/train.py \
  --dataset_path=/path/to/your/dataset \
  --export_path=/path/to/export/model

```

Here are some flags that you can use to configure the training:

| Flag                  | Required | Type     | Description                                  | Default Value |
|-----------------------|----------|----------|----------------------------------------------|---------------|
| `--dataset_path`      | `true`   | `string` | Directory to save the model                  | `None`        |
| `--export_path`       | `true`   | `string` | Path to export the model                     | `None`        |
| `--augment_data`      | `false`  | `bool`   | Whether to augment the data                  | `False`       |
| `--batch_size`        | `false`  | `int`    | The batch size of the model                  | `200`         |
| `--tpu`               | `false`  | `string` | The address of the TPU to connect to         | `""`          |
| `--num_epochs`        | `false`  | `int`    | The number of epochs to train for            | `10`          |
| `--validation_split`  | `false`  | `float`  | The percentage of validation split           | `0.2`         |
| `--pre_trained_model` | `false`  | `string` | The pre-trained model to use                 | `MobileNetV2` |
| `--weights`           | `false`  | `string` | The weights to use for the pre-trained model | `imagenet`    |

## Convert to TFLite

To convert your `SavedModel` file generated by `train.py`, you can use the `convert.py` script.

```shell
python3 src/convert.py \
  --model_path=/path/to/saved/model \
  --export_path=/path/to/export/tflite/model

```

Here are some flags that you can use to configure the conversion:

| Flag            | Required | Type     | Description                     | Default Value       |
|-----------------|----------|----------|---------------------------------|---------------------|
| `--model_path`  | `true`   | `string` | Path to the SavedModel file     | `None`              |
| `--export_path` | `false`  | `string` | Path to export the TFLite model | `"converted_model"` |
